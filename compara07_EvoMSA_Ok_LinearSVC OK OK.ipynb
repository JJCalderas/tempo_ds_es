{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7184ee9-874c-4468-8162-937f44fa7b4f",
   "metadata": {},
   "source": [
    "Con EvomSA y LinearSVC\n",
    "4 Modelos combinados 12 (de los modelos no tiene al MeOffendEs pre-entrenado)\n",
    "y 7 DS en Es incluyendo MeOfendeEs (como train/text)\n",
    "12x7=84\n",
    "\n",
    "Falta:\n",
    "Vulgarity\n",
    "\n",
    "Solo Aplico EvoMSA. Faltarian los otros (Idf-Tf, NB, mTC corre con LinearSVC, EvoMSA corre con EvoDAGE + GaussianNB, FastText + Sinonimos(transitivos) + NCR-Emotion-Lexicon-Es(MX.bin + Cluster) )\n",
    "++ Hate Speech Detection Using a Convolution-LSTM Based Deep Neural Network\n",
    "++ Detection of Offensive Tweets: A Comparative Study\n",
    "++ Varios articulos en: C:\\Users\\juan\\Documents\\DCCD\\articulos\n",
    "k-fold\n",
    "Intervalo de Confianza\n",
    "Jaccard similarity From https://text-models.readthedocs.io/en/latest/voc.html#voc para establecer Relacion\n",
    "cosine distanc\n",
    "PCA\n",
    "\n",
    "\n",
    "Genetic Algorithm + EvoDAG\n",
    "EvoMSA\n",
    "\n",
    "En el PDF \"las17 CD Grapgh.pdf\" es un articulo acerda de la CD graph.\n",
    "\n",
    "demsar06a.pdf \"Statistical Comparisons of Classifiers over Multiple Data Sets\" tiene graficas comparativas de clasificadores.\n",
    "\n",
    "http://localhost:8889/lab\n",
    "\n",
    "# Ya esta en la tabla EvoMSA_dsEs_mAll_LienarSVC\n",
    "\n",
    "Survey of Text Classifiers for Offensive Language in Short Text used in RRSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab15a7dc-834d-42d2-8f5a-ec4035bfcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import winsound\n",
    "import time\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as model_selection\n",
    "from EvoMSA.base import EvoMSA\n",
    "from EvoMSA.model import TextModelInv\n",
    "from microtc.textmodel import TextModel\n",
    "from sklearn import metrics\n",
    "from microtc.utils import load_model\n",
    "from microtc.utils import save_model\n",
    "from EvoMSA.utils import download\n",
    "\n",
    "usar = \"sklearn.svm.LinearSVC\"\n",
    "# usar = \"sklearn.naive_bayes.BernoulliNB\"\n",
    "# usar = \"sklearn.naive_bayes.MultinomialNB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67bd12da-2e7d-4d39-bf24-c5d34fc4556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#misoginia = download('misoginia_Es.evomsa')\n",
    "#save_model(misoginia, 'models/misoginia_Es.evomsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6411b779-aa40-4d60-902c-20e8e58c64ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\anaconda3\\envs\\orange3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\juan\\anaconda3\\envs\\orange3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianNB from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reverse_model = [load_model('models\\\\text_model_inv_simple.evomsa'), usar]\n",
    "haha_model = [load_model('models\\\\haha2018_Es.evomsa'), usar]\n",
    "mexa3t_model = [load_model('models\\\\mexa3t2018_aggress_Es.evomsa'), usar]\n",
    "misoginia_model = [load_model('models\\\\misoginia_Es.evomsa'), usar]\n",
    "#misoginia_model = [download('misoginia_Es.evomsa'), usar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5962e17-0ff0-4dcf-8cc3-6786afdd5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [\n",
    "      [],\n",
    "      [reverse_model], \n",
    "      [haha_model], \n",
    "      [mexa3t_model], \n",
    "      [misoginia_model], \n",
    "\n",
    "      [reverse_model, haha_model], \n",
    "      [reverse_model, misoginia_model], \n",
    "      [reverse_model, mexa3t_model], \n",
    "      [haha_model, mexa3t_model], \n",
    "      [haha_model, misoginia_model], \n",
    "    \n",
    "      [haha_model, mexa3t_model, misoginia_model], \n",
    "    \n",
    "      [reverse_model, haha_model, mexa3t_model, misoginia_model]\n",
    "    ]\n",
    "\n",
    "M = [[misoginia_model, reverse_model, haha_model, mexa3t_model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1078a46d-edc0-4ec2-a7ce-e7a3bf56ba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "from EvoMSA import __version__ as version\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efea1c6b-3025-4e40-8980-a8879d56deed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPara TextosCortos, no es recomendable quitar los Stopwords\\n\\nfrom nltk.corpus import stopwords\\nfrom textblob import TextBlob\\n\\ndef removeStopwords( texto):\\n    blob = TextBlob(texto.lower()).words\\n    outputlist = [word for word in blob if word not in stopwords.words('spanish')]\\n    return(' '.join(word for word in outputlist))\\n\\nprint(removeStopwords('las Cosas sin sentidos DCHAS ichas por el guason el a침o pasado han sido una nefasta decisi칩n de todos y no o si por las dudas de los angeles mal escirto'))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Para TextosCortos, no es recomendable quitar los Stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "def removeStopwords( texto):\n",
    "    blob = TextBlob(texto.lower()).words\n",
    "    outputlist = [word for word in blob if word not in stopwords.words('spanish')]\n",
    "    return(' '.join(word for word in outputlist))\n",
    "\n",
    "print(removeStopwords('las Cosas sin sentidos DCHAS ichas por el guason el a침o pasado han sido una nefasta decisi칩n de todos y no o si por las dudas de los angeles mal escirto'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67b440-8824-4d84-9e40-5b751dbb47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "## se llama semeval2018_anger_Es\n",
    "\n",
    "# los models son es Es, entonces solo ds en Es\n",
    "# fnames = glob(\"dataset_Es/*_train.json\")\n",
    "fnames = glob(\"dataset/haha2018_Es_train.json\")\n",
    "fnames.sort()\n",
    "\n",
    "p_ds_m = []\n",
    "for fn in fnames:\n",
    "    \n",
    "    train_df = pd.read_json(fn, lines=True)\n",
    "    test_df = pd.read_json(fn.replace(\"_train\", \"_test\"), lines=True)\n",
    "    \n",
    "    # recortarlos\n",
    "    #train_df = train_df.loc[0:49, ['text', 'klass']]\n",
    "    #test_df = test_df.loc[0:49, ['text', 'klass']]\n",
    "\n",
    "    if False: # BiFrases ya no aplican\n",
    "        _ = train_df.iloc[0]\n",
    "        bi_train_df = pd.DataFrame([_], columns = ['text', 'klass'])\n",
    "        for index, row in train_df.iloc[1:].iterrows():\n",
    "            try:\n",
    "                row['text'] = removeStopwords(row['text'])\n",
    "                bi_train_df =  bi_train_df.append(row)\n",
    "                if _['klass'] == row['klass']:\n",
    "                    bi_frase = {'text': _['text'] + ' ' + row['text'], 'klass':row['klass']}\n",
    "                    bi_train_df = bi_train_df.append(bi_frase, ignore_index=True)\n",
    "                    _ =  {'text': '_V_A_C_I_A_', 'klass': None}\n",
    "                else:   \n",
    "                    _ = row\n",
    "            except Exception as exc:\n",
    "                print(exc)\n",
    "                _ = row\n",
    "                continue\n",
    "        train_df = bi_train_df\n",
    "    \n",
    "    X_train = train_df[['text']]\n",
    "    y_train = train_df[['klass']]\n",
    "    \n",
    "    X_test = test_df[['text']]\n",
    "    y_test = test_df[['klass']]\n",
    "    \n",
    "    ds_n = fn.replace(\"dataset_Es/\",'').replace(\"dataset_Es\\\\\",'').replace('_train.json','')\n",
    "    #p_m = []    \n",
    "    print('__',ds_n,'___')\n",
    "    for m in M:\n",
    "        print('> ', m)\n",
    "        evo = EvoMSA(TR=True, B4MSA=False, lang='es', Emo=True, Aggress=True, stacked_method='sklearn.svm.LinearSVC',models=m) \n",
    "        # sklearn.svm.LinearSVC\n",
    "        # sklearn.naive_bayes.GaussianNB\n",
    "        evo.fit(X_train.squeeze(), y_train.squeeze())\n",
    "    \n",
    "        pred = evo.predict(X_test.squeeze())\n",
    "        \n",
    "        recall_score = metrics.recall_score(pred, y_test, average=\"macro\")\n",
    "        precision_score = metrics.precision_score(pred, y_test, average=\"macro\")\n",
    "        f1_score = metrics.f1_score(pred, y_test, average=\"macro\")\n",
    "        f1_score_micro = metrics.recall_score(pred, y_test, average=\"micro\")\n",
    "    \n",
    "        _ = [ds_n, recall_score, f1_score, precision_score, f1_score_micro]\n",
    "\n",
    "        p_ds_m.append(_)\n",
    "        print(\"{0}, {1:1.6f}, {2:1.6f}, {3:1.6f}, {4:1.6f}\".format(_[0], _[1], _[2], _[3], _[4]))\n",
    "        \n",
    "        winsound.Beep(4500, 300)\n",
    "    #print(p)\n",
    "    #p_ds.append(p_m)\n",
    "    winsound.Beep(3000, 900)\n",
    "    \n",
    "    #break\n",
    "    \n",
    "winsound.Beep(2500, 1600)    \n",
    "\n",
    "for p in p_ds_m:\n",
    "    # print(p)\n",
    "    print(\"{0}, {1:1.6f}, {2:1.6f}, {3:1.6f}, {4:1.6f}\".format(p[0], p[1], p[2], p[3], p[4]))    \n",
    "    # print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (accuracy, macro_f1, macro_recall, macro_precision, micro_f1))\n",
    "\n",
    "print(time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37e8fd35-be90-4ab2-9afa-3d0c1f774852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminado\n"
     ]
    }
   ],
   "source": [
    "print('Terminado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbb27e0e-f8d9-4fcf-b59f-aa32c83f8b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847769, 0.844047, 0.840919, 0.855500\n"
     ]
    }
   ],
   "source": [
    "for p in p_ds_m:\n",
    "    # print(p)\n",
    "    print(\"{0:1.6f}, {1:1.6f}, {2:1.6f}, {3:1.6f}\".format(p[1], p[2], p[3], p[4]))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e0f4c-f2c5-4f43-9138-65d0aabab8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(p_ds, 'EvoMSA_dsEs_mAll_LinearSVC.scores')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d23cb6-76a0-48b3-90c3-20784122d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ds_n, recall_score, f1_score, precision_score, f1_score_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf1d0a-be44-4648-888e-1111e6c7a8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
