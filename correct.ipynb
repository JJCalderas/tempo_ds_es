{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ba695b-2cfd-4dbe-bd5b-48d1f23a27be",
   "metadata": {},
   "source": [
    "- Usar otros Clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160c008c-f350-4ff5-b51e-e278bbfaf493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import winsound\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "count_vect = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7631490-67dd-491a-b9cc-0c777add2ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fnames = glob(\"datasets/*_train.json\")\n",
    "#fnames = glob(\"datasets/meoffendes2021_mx_Es_train.json\")\n",
    "fnames = glob(\"datasets/haha2018_Es_train.json\")\n",
    "fnames.sort()\n",
    "\n",
    "fn = fnames[0]\n",
    "df = pd.read_json(fn, lines=True)\n",
    "train_df = pd.read_json(fn, lines=True)\n",
    "test_df = pd.read_json(fn.replace(\"_train\", \"_test\"), lines=True)\n",
    "train = train_df.loc[0:99, ['text', 'klass']]\n",
    "test = test_df.loc[0:39, ['text', 'klass']]\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20bddd-8df5-4103-8e80-da25ecffe946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3166ab8e-7ccd-4e9c-95a6-9202bac58133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__ /haha2018_Es ___\n",
      "train_df >  (6000, 2)\n",
      "Test >  (3000, 2)\n",
      "dataset, accuracy, f1_macro, precision_macro, recall_macro, f1_micro\n",
      "/haha2018_Es, 0.74000, 0.73096, 0.72870, 0.74224, 0.74000\n"
     ]
    }
   ],
   "source": [
    "P = []\n",
    "for fn in fnames:\n",
    "\n",
    "    ds_n = fn.replace(\"datasets\",'').replace('_train.json','')\n",
    "    print('__', ds_n, '___')\n",
    "\n",
    "    train_df = pd.read_json(fn, lines=True)\n",
    "    test_df = pd.read_json(fn.replace(\"_train\", \"_test\"), lines=True)\n",
    "\n",
    "    # recortados para pruebas\n",
    "    train_df = train_df.loc[0:5999, ['text', 'klass']]\n",
    "    test_df = test_df.loc[0:2999, ['text', 'klass']]\n",
    "    \n",
    "    ############\n",
    "    ## Cambiar True/False para usar o no las BiFrases\n",
    "    ###########\n",
    "    if False:\n",
    "        \"\"\"\n",
    "        TODO: en cada append, el dataset se reconstruye completo. Encontrar otro método más rápido.\n",
    "        \"\"\"\n",
    "        _ = train_df.iloc[0]\n",
    "        bi_train_df = pd.DataFrame([_], columns = ['text', 'klass'])\n",
    "        for index, row in train_df.iloc[1:].iterrows():\n",
    "            try:\n",
    "                bi_train_df =  bi_train_df.append(row)\n",
    "                if _['klass'] == row['klass']:\n",
    "                    bi_frase = {'text': _['text'] + ' ' + row['text'], 'klass':row['klass']}\n",
    "                    bi_train_df = bi_train_df.append(bi_frase, ignore_index=True)\n",
    "                    _ =  {'text': '_V_A_C_I_A_', 'klass': None}\n",
    "                else:   \n",
    "                    _ = row\n",
    "            except Exception as exc:\n",
    "                print(exc)\n",
    "                _ = row\n",
    "                continue\n",
    "        ('train_df Bi> ', train_df.shape, ' > ', bi_train_df.shape)\n",
    "        train_df = bi_train_df\n",
    "        winsound.Beep(3000, 900)\n",
    "\n",
    "    print('train_df > ', train_df.shape)\n",
    "    print('Test > ', test_df.shape)\n",
    "    \n",
    "    X_train = train_df[['text']]\n",
    "    y_train = train_df[['klass']]\n",
    "    \n",
    "    X_test = test_df[['text']]\n",
    "    y_test = test_df[['klass']]\n",
    "    \n",
    "    \n",
    "    X_train_counts = count_vect.fit_transform(X_train['text'])    \n",
    "    MNB = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False)\n",
    "    MNB.fit(X_train_counts, y_train.values.ravel())\n",
    "    X_test_counts = count_vect.transform(X_test['text'])\n",
    "    predicted = MNB.predict(X_test_counts)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    v = TfidfVectorizer(use_idf = True)\n",
    "    x = v.fit_transform(X_train['text']).toarray()\n",
    "    GNB = GaussianNB()\n",
    "    GNB.fit(x, y_train.values.ravel())\n",
    "    y = v.transform(X_test['text']).toarray()\n",
    "    predicted = GNB.predict(y)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    v = TfidfVectorizer(use_idf = True)\n",
    "    x = v.fit_transform(X_train['text']).toarray()\n",
    "    DT = DecisionTreeClassifier()\n",
    "    DT.fit(x, y_train)\n",
    "    y = v.transform(X_test['text']).toarray()\n",
    "    predicted = DT.predict(y)\n",
    "    '''\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    f1_score = metrics.f1_score(y_test, predicted, average=\"macro\")\n",
    "    precision_score = metrics.precision_score(y_test, predicted, average=\"macro\")\n",
    "    recall_score = metrics.recall_score(y_test, predicted, average=\"macro\")\n",
    "    f1_score_micro = metrics.recall_score(y_test, predicted, average=\"micro\")\n",
    "    \n",
    "    p = [ds_n, accuracy, f1_score, precision_score, recall_score, f1_score_micro] \n",
    "    P.append(p)\n",
    "\n",
    "    winsound.Beep(3000, 900)\n",
    "    \n",
    "    #break\n",
    "\n",
    "#save_model(P, 'MNB_BiFrases_True.scores')    \n",
    "    \n",
    "winsound.Beep(1500, 1000) \n",
    "\n",
    "print('dataset,', 'accuracy,', 'f1_macro,', 'precision_macro,', 'recall_macro,', 'f1_micro')\n",
    "for p in P:\n",
    "    print(\"{0}, {1:1.5f}, {2:1.5f}, {3:1.5f}, {4:1.5f}, {5:1.5f}\".format(p[0], p[1], p[2], p[3], p[4], p[5]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0462ec3-5f84-4b48-81e1-450852940b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df >  (6000, 2)\n",
      "Test >  (3000, 2)\n",
      "dataset, accuracy, f1_macro, precision_macro, recall_macro, f1_micro\n",
      "/haha2018_Es, 0.74000, 0.73096, 0.72870, 0.74224, 0.74000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78      1888\n",
      "           1       0.62      0.75      0.68      1112\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.73      0.74      0.73      3000\n",
      "weighted avg       0.76      0.74      0.74      3000\n",
      "\n",
      "[[1385  503]\n",
      " [ 277  835]]\n"
     ]
    }
   ],
   "source": [
    "# FALSE\n",
    "print('train_df > ', train_df.shape)\n",
    "print('Test > ', test_df.shape)\n",
    "print('dataset,', 'accuracy,', 'f1_macro,', 'precision_macro,', 'recall_macro,', 'f1_micro')\n",
    "for p in P:\n",
    "    print(\"{0}, {1:1.5f}, {2:1.5f}, {3:1.5f}, {4:1.5f}, {5:1.5f}\".format(p[0], p[1], p[2], p[3], p[4], p[5]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "494b7478-389a-450a-bde3-60597518ea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df >  (6000, 2)\n",
      "Test >  (3000, 2)\n",
      "dataset, accuracy, f1_macro, precision_macro, recall_macro, f1_micro\n",
      "/haha2018_Es, 0.74000, 0.73096, 0.72870, 0.74224, 0.74000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78      1888\n",
      "           1       0.62      0.75      0.68      1112\n",
      "\n",
      "    accuracy                           0.74      3000\n",
      "   macro avg       0.73      0.74      0.73      3000\n",
      "weighted avg       0.76      0.74      0.74      3000\n",
      "\n",
      "[[1385  503]\n",
      " [ 277  835]]\n"
     ]
    }
   ],
   "source": [
    "# TRUE\n",
    "print('train_df > ', train_df.shape)\n",
    "print('Test > ', test_df.shape)\n",
    "print('dataset,', 'accuracy,', 'f1_macro,', 'precision_macro,', 'recall_macro,', 'f1_micro')\n",
    "for p in P:\n",
    "    print(\"{0}, {1:1.5f}, {2:1.5f}, {3:1.5f}, {4:1.5f}, {5:1.5f}\".format(p[0], p[1], p[2], p[3], p[4], p[5]))\n",
    "\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5a1eb-55e3-4d83-bd7c-4816e8eb7ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
