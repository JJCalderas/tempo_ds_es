{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3268246c-4d03-4b40-9fe2-1324c860a686",
   "metadata": {},
   "source": [
    "### Correr EvoMSA por cada DS y con todos los SinglePreModels\n",
    "\n",
    "- Haha21\n",
    "- Exist21\n",
    "- FakDes21\n",
    "- MeOffendEs21\n",
    "- DaVincis22\n",
    "- Misogyny\n",
    "- Semeval18 (anger, fear)\n",
    "- MexA3t18_anger\n",
    "- Detest22\n",
    "- Detoxis21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26521670-cb74-4977-b53e-edcde6274da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  threading import Thread\n",
    "from time import sleep, perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55538e7-ea5a-49b9-8322-8025c10a3112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EvoMSA.base import EvoMSA\n",
    "from microtc.utils import load_model\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "675c060a-22b9-4cc5-8b8c-00d571b16291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.6\n"
     ]
    }
   ],
   "source": [
    "from EvoMSA import __version__ as version\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c8a72e-ad7b-453c-9f63-7445b5181366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\anaconda3\\envs\\orange3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LinearSVC from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\juan\\anaconda3\\envs\\orange3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator GaussianNB from version 0.22.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "stacked_method = \"sklearn.svm.LinearSVC\"\n",
    "# usar = \"sklearn.naive_bayes.BernoulliNB\"\n",
    "# usar = \"sklearn.naive_bayes.MultinomialNB\"\n",
    "\n",
    "davincis22 = [load_model('../../single_models/davincis22_single_Es.evomsa'), stacked_method]\n",
    "exist22 = [load_model('../../single_models/exist21_single_Es.evomsa'), stacked_method]\n",
    "fakedes2021 = [load_model('../../single_models/fakedes2021_single_Es.evomsa'), stacked_method]\n",
    "haha21 = [load_model('../../single_models/haha21_single_Es.evomsa'), stacked_method]\n",
    "meoffendes21 = [load_model('../../single_models/meoffendes21_single_Es.evomsa'), stacked_method]\n",
    "mexa3t2018_aggress = [load_model('../../single_models/mexa3t2018_aggress_single_Es.evomsa'), stacked_method]\n",
    "misogyny = [load_model('../../single_models/misogyny_single_Es.evomsa'), stacked_method]\n",
    "semeval2018_anger = [load_model('../../single_models/semeval2018_anger_single_Es.evomsa'), stacked_method]\n",
    "semeval2018_fear = [load_model('../../single_models/semeval2018_fear_single_Es.evomsa'), stacked_method]\n",
    "\n",
    "mexa3t_model = [load_model('../../models/mexa3t2018_aggress_Es.evomsa'), stacked_method]\n",
    "misoginia_model = [load_model('../../models/misoginia_Es.evomsa'), stacked_method]\n",
    "\n",
    "mm = [davincis22, exist22, fakedes2021, haha21, meoffendes21, mexa3t2018_aggress, misogyny, semeval2018_anger, semeval2018_fear]\n",
    "#evo = EvoMSA(TR=True, B4MSA=False, lang='es', Emo=True, Aggress=True, stacked_method=stacked_method, models= mm)\n",
    "\n",
    "#for m in mm:\n",
    "#    print('> ', m)\n",
    "#    evo = EvoMSA(TR=True, B4MSA=False, lang='es', Emo=True, Aggress=True, stacked_method=stacked_method, models= m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c40f8f6-16ea-4ac7-a521-db23ed42a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(fn):\n",
    "    \n",
    "    train_df = pd.read_json(fn, lines=True)\n",
    "    test_df = pd.read_json(fn.replace(\"_train\", \"_test\"), lines=True)\n",
    "\n",
    "    X_train = train_df[['text']]\n",
    "    y_train = train_df[['klass']]\n",
    "    \n",
    "    X_test = test_df[['text']]\n",
    "    y_test = test_df[['klass']]\n",
    "    \n",
    "    ds_n = fn.replace(\"../../dataset_Es\\\\\",'').replace('_Es_train.json','')\n",
    "    \n",
    "    print(ds_n)\n",
    "    \n",
    "    # single\n",
    "    evo = EvoMSA(TR=True, B4MSA=False, lang='es', Emo=True, Aggress=True, stacked_method=stacked_method, models= [])\n",
    "    evo.fit(X_train.squeeze(), y_train.squeeze())\n",
    "    pred = evo.predict(X_test.squeeze())\n",
    "    recall_score_single = metrics.recall_score(pred, y_test, average=\"macro\")\n",
    "    f1_score_single = metrics.f1_score(pred, y_test, average=\"macro\")\n",
    "    \n",
    "    # multiple\n",
    "    evo = EvoMSA(TR=True, B4MSA=False, lang='es', Emo=True, Aggress=True, stacked_method=stacked_method, models= mm)\n",
    "    evo.fit(X_train.squeeze(), y_train.squeeze())\n",
    "    pred = evo.predict(X_test.squeeze())\n",
    "    recall_score_multiple = metrics.recall_score(pred, y_test, average=\"macro\")\n",
    "    f1_score_multiple = metrics.f1_score(pred, y_test, average=\"macro\")\n",
    "\n",
    "    _ = [ds_n, X_train.shape, recall_score_single, f1_score_single, recall_score_multiple, f1_score_multiple]\n",
    "    \n",
    "    results.append(_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff0009-1459-48d0-b501-25363bff5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob(\"../../dataset_Es/*_train.json\")\n",
    "fnames.sort()\n",
    "\n",
    "results = []\n",
    "start_time = perf_counter()\n",
    "threads = []\n",
    "for fn in fnames:\n",
    "    \n",
    "    tsk = Thread(target=task, args=(fn,))\n",
    "    threads.append(tsk)\n",
    "    tsk.start()\n",
    "\n",
    "for tsk in threads:\n",
    "    tsk.join()\n",
    "\n",
    "end_time = perf_counter()\n",
    "\n",
    "print(f'It took {end_time- start_time: 0.2f} second(s) to complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae2a43-5eba-47ee-a684-88a26bfb8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cffcc273-ce70-4246-8dca-01ffa6c17597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from microtc.utils import save_model\n",
    "#save_model(results, 'resullts_multiple_01.metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e9ca254-968f-403e-9841-ddcf28d7e3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet</th>\n",
       "      <th>shape</th>\n",
       "      <th>s-recall</th>\n",
       "      <th>s-f1</th>\n",
       "      <th>m-recall</th>\n",
       "      <th>m-f1</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semeval2018_sadness</td>\n",
       "      <td>(1350, 1)</td>\n",
       "      <td>0.360507</td>\n",
       "      <td>0.408195</td>\n",
       "      <td>0.424273</td>\n",
       "      <td>0.430897</td>\n",
       "      <td>-0.022702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>semeval2018_joy</td>\n",
       "      <td>(1260, 1)</td>\n",
       "      <td>0.512070</td>\n",
       "      <td>0.481660</td>\n",
       "      <td>0.502229</td>\n",
       "      <td>0.479207</td>\n",
       "      <td>0.002452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>semeval2018_anger</td>\n",
       "      <td>(1359, 1)</td>\n",
       "      <td>0.420269</td>\n",
       "      <td>0.396493</td>\n",
       "      <td>0.422241</td>\n",
       "      <td>0.419181</td>\n",
       "      <td>-0.022687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semeval2018_fear</td>\n",
       "      <td>(1368, 1)</td>\n",
       "      <td>0.528177</td>\n",
       "      <td>0.482220</td>\n",
       "      <td>0.490019</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.008920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semeval2018_valence</td>\n",
       "      <td>(1795, 1)</td>\n",
       "      <td>0.334615</td>\n",
       "      <td>0.322807</td>\n",
       "      <td>0.347622</td>\n",
       "      <td>0.334407</td>\n",
       "      <td>-0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meoffendes2021</td>\n",
       "      <td>(3795, 1)</td>\n",
       "      <td>0.793131</td>\n",
       "      <td>0.755097</td>\n",
       "      <td>0.738193</td>\n",
       "      <td>0.675904</td>\n",
       "      <td>0.079193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>exist2021</td>\n",
       "      <td>(2655, 1)</td>\n",
       "      <td>0.746018</td>\n",
       "      <td>0.745777</td>\n",
       "      <td>0.741563</td>\n",
       "      <td>0.740359</td>\n",
       "      <td>0.005419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>davincis2022</td>\n",
       "      <td>(2521, 1)</td>\n",
       "      <td>0.770896</td>\n",
       "      <td>0.769870</td>\n",
       "      <td>0.771220</td>\n",
       "      <td>0.767608</td>\n",
       "      <td>0.002262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mexa3t2018_aggress</td>\n",
       "      <td>(5389, 1)</td>\n",
       "      <td>0.793277</td>\n",
       "      <td>0.789327</td>\n",
       "      <td>0.801422</td>\n",
       "      <td>0.794541</td>\n",
       "      <td>-0.005214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>haha2021</td>\n",
       "      <td>(18000, 1)</td>\n",
       "      <td>0.842803</td>\n",
       "      <td>0.836869</td>\n",
       "      <td>0.852546</td>\n",
       "      <td>0.837146</td>\n",
       "      <td>-0.000277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DataSet       shape  s-recall      s-f1  m-recall      m-f1  \\\n",
       "0  semeval2018_sadness   (1350, 1)  0.360507  0.408195  0.424273  0.430897   \n",
       "1      semeval2018_joy   (1260, 1)  0.512070  0.481660  0.502229  0.479207   \n",
       "2    semeval2018_anger   (1359, 1)  0.420269  0.396493  0.422241  0.419181   \n",
       "3     semeval2018_fear   (1368, 1)  0.528177  0.482220  0.490019  0.473300   \n",
       "4  semeval2018_valence   (1795, 1)  0.334615  0.322807  0.347622  0.334407   \n",
       "5       meoffendes2021   (3795, 1)  0.793131  0.755097  0.738193  0.675904   \n",
       "6            exist2021   (2655, 1)  0.746018  0.745777  0.741563  0.740359   \n",
       "7         davincis2022   (2521, 1)  0.770896  0.769870  0.771220  0.767608   \n",
       "8   mexa3t2018_aggress   (5389, 1)  0.793277  0.789327  0.801422  0.794541   \n",
       "9             haha2021  (18000, 1)  0.842803  0.836869  0.852546  0.837146   \n",
       "\n",
       "       diff  \n",
       "0 -0.022702  \n",
       "1  0.002452  \n",
       "2 -0.022687  \n",
       "3  0.008920  \n",
       "4 -0.011600  \n",
       "5  0.079193  \n",
       "6  0.005419  \n",
       "7  0.002262  \n",
       "8 -0.005214  \n",
       "9 -0.000277  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = load_model('../results/resullts_multiple_01.metrics')\n",
    "df = pd.DataFrame(lst, columns=['DataSet', 'shape', 's-recall', 's-f1', 'm-recall', 'm-f1'])\n",
    "df['diff'] = df['s-f1'] - df['m-f1']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81817920-1de6-4371-a819-9d0bcabe23de",
   "metadata": {},
   "source": [
    "- Cada renglon es un Dataset (train.json)\n",
    "- single: sin usar pre-modelos EvoMSA\n",
    "- multiple: usando todos los pre-modelos EvoMSA (No se aplicoo: excepto el evaluado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf3102-d7c9-488f-bba6-2b0a7009cbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
